
CROKAGE_HOME=/home/rodrigo/projects/crokage-tool
TMP_DIR=/home/rodrigo/tmp

#CROKAGE_HOME=/home/user/crokage-replication-package
#TMP_DIR=/home/user/tmp

###see options below to set the action

################ API tools actions

# buildMatrixForKappaBeforeAgreement      = use QuestionsToEvaluate.xlsx to build MatrixForKappa.csv
# buildFileForAgreementPhaseHighlightingDifferences = process QuestionsToEvaluate.xlsx and build QueriesAndAnswersAgreement.xlsx with XXX where likert difference is > 1
# buildMatrixForKappaAfterAgreement      = use QueriesAndAnswersAgreement.xlsx to build MatrixForKappa.csv 
# loadGroundTruthSelectedQueries         = load queries and evaluations considering only queries whose answers contain at least one 4 likert
# checkConditions						 = used to check conditions to run the approach
# extractAPIsFromRACK             		  = extracts APIs from RACK approach
# extractAPIsFromBIKER             		  = extracts APIs from BIKER approach
# extractAPIsFromNLP2Api				  = extracts APIs from NLP2Api approach
# getApisForApproaches                    = extracts APIs from all approaches
# loadExcelGroundTruthQuestionsAndLikerts = load excel files containing likerts for external questions - ground truth
#                                           subAction may also contains ...|generateTableForApproaches to print a string that can be used to paste into overleaf representing the lines of a table
# generateInvertedIndexFileFromSOPosts    = fetches posts containing code, extract classes and build a file with inverted indexes in a format like: api-> postID1, postID2 ...   
# generatePostsApisMap                    = fetches posts containing code, extract classes and build a file with a map of classes for each post like: postId-> api1, api2...
# loadPostsApisMap
# reduceBigMapFileToMininumAPIsCount      = loads the big file, set cutoff to the minimum amount of ids each class should have and generate reduced map
# loadInvertedIndexFile					  = loads the reduced file containing the indexes and stores into a map	
## preprocess another project
# generateTrainingFileToFastText		  = generate a txt file containing all posts contents (pre processed)
# buildSODirectoryFiles				      = build a txt file representing each post to be used by lucene
# buildLuceneIndex						  = build lucene index	
# buildIDFVocabulary					  = build IDFs for all words in vocabulary	
# readIDFVocabulary					  	  = read IDFs for all words in vocabulary from a file
## build fastText wordvec txt file        = built by command line. Use .bin model to build the txt file with words and their vectors.
# readSoContentWordVectors				  = read vectors of all words from txt file, previously generated by fastText in shell

################ Main parameters: ################################### 
# runApproach							  = test retrieval mechanism 
# extractAnswers						  = generate summaries with code sentences and explanations. subAction = saveCache|useRecommendedCache. saveCache will save in a file the recommended results for each query. useRecommendedCache will use these saved results instead of calling approach. Test in lowercase.
# generateMetricsForApiExtractors 		  = extract metrics for the apis. Set subAction to RACK|BIKER|NLP2Api or a combination of them like BIKER|NLP2Api for BICKER + NLP2API or RACK|BIKER|NLP2Api for the three of them (the order matters !) 

## vm atributes: -Xms512m -Xmx15000m  

action=runApproach

#best combination of tools: rack|BIKER|NLP2Api
subAction=rack|biker|NLP2Api|savecache|useRecommendedCache


# values= nlp2api|selectedqueries-training49|selectedqueries-user-study
dataSet=selectedqueries-training49

MODEL_VECTOR_SIZE=200

BM25_K = 1.2
BM25_B = 0.9 

################################ Ranking parameters when using classes #####################################################################

#Rank the first top-BM25Limit2 scored answers in BM25 to be merged with the output of the asymmetric relevance mechanism
bm25TopNSmallLimit=100

numberOfComposedAnswers=5

semWeight   =1.0
methodWeight=0.75
tfIdfWeight =0.50
bm25Weight  =0.50


######### Must to be provided or generated via method call


# generated by method call - a map containing all apis and their answers ids
BIG_MAP_INVERTED_INDEX_APIS_FILE_PATH = ${TMP_DIR}/bigMap.txt
# generated by method call by the same method above - answer ids disconsidered because have no api calls
SO_UPVOTED_POSTS_WITH_CODE_APIS_FILE = ${TMP_DIR}/soUpvotedPostsWithCodeAPIsMap.txt

# generated by method call. Contains titles, bodies and code of SO posts, one per line
SO_CONTENT_FILE = ${TMP_DIR}/soContent.txt
# generated by method call. From so content file, calculate the idf of all words and save in this file.
SO_IDF_VOCABULARY = ${TMP_DIR}/soIDFVocabulary.txt
# generated in shell through fastText commands. Uses the file above. Contains word vectors for each word of the titles vocabulary.
SO_CONTENT_WORD_VECTORS = ${TMP_DIR}/soContentWordVec.txt
# generated by method call. To be used by lucene to build idf voc.
SO_DIRECTORY_FILES =  ${TMP_DIR}/sodirectory
# generated by method call. To be used by lucene to build idf voc.
SO_DIRECTORY_INDEX =  ${TMP_DIR}/sodirindex

# to evaluate questions to queries. Can be .csv or .ods
QUERIES_AND_SO_ANSWERS_TO_EVALUATE =${CROKAGE_HOME}/data/QuestionsToEvaluate

QUERIES_AND_SO_ANSWERS_AGREEMENT =${CROKAGE_HOME}/data/QueriesAndAnswersAgreement.xlsx


#Answers directory
ANSWERS_DIRECTORY = ${CROKAGE_HOME}/data/answers

#BIKER summaries answers
BIKER_ANSWERS_SUMMARIES_TRAINING=${CROKAGE_HOME}/data/bikerAnswersTraining/Top10

######### Must to be generated or provided for tests

 #for tests - static file - must be provided
NLP2API_GOLD_SET_FILE = ${CROKAGE_HOME}/data/nlp2ApiGoldSet.txt
INPUT_QUERIES_FILE_NLP2API = ${CROKAGE_HOME}/data/inputQueriesNlp2Api.txt

INPUT_QUERIES_FILE_TRAINING=${CROKAGE_HOME}/data/selectedqueries-training49.txt
INPUT_QUERIES_FILE_TEST=${CROKAGE_HOME}/data/selectedqueries-test48.txt
INPUT_QUERIES_FILE_USER_STUDY=${CROKAGE_HOME}/data/selectedqueries-user-study.txt

STOP_WORDS_FILE_PATH=${CROKAGE_HOME}/data/stanford_stop_words.txt

RECOMMENDED_ANSWERS_QUERIES_CACHE =${CROKAGE_HOME}/data/recommendedAnswersQueriesCache

######### Automatically generated files

#generated to be read by BIKER

CROKAGE_HOME_DATE_FOLDER= ${CROKAGE_HOME}/data/

#generated after calling NLP2Api jar
RACK_OUTPUT_QUERIES_FILE = rackApiQueriesOutput.txt

#generated after calling NLP2Api jar
NLP2API_OUTPUT_QUERIES_FILE = nlp2apiQueriesOutput.txt

MATRIX_KAPPA_BEFORE_AGREEMENT = ${CROKAGE_HOME}/data/MatrixForKappaBeforeAgreement.csv
MATRIX_KAPPA_AFTER_AGREEMENT = ${CROKAGE_HOME}/data/MatrixForKappaAfterAgreement.csv

############################## Database and Spring parameters ######################################

debug=false
server.port= 8080
logging.path=/home/rodrigo/tmp
logging.file=/home/rodrigo/tmp/crokageToolBackEnd.log
#server.port= 80

spring.jpa.database=POSTGRESQL
spring.datasource.platform=postgres
spring.jpa.show-sql=true
spring.jpa.hibernate.ddl-auto=none
spring.database.driverClassName=org.postgresql.Driver
spring.devtools.livereload.enabled = false

endpoints.cors.allowed-origins=*
spring.jpa.show-sql=false
logging.config = classpath:logback.xml

spring.datasource.url=jdbc:postgresql://localhost:5432/stackoverflow2018crokagereplicationpackage
spring.datasource.username=postgres
spring.datasource.password=lascampostgres5k