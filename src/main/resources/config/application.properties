debug=false
server.port= 8080
#server.port= 80

spring.jpa.database=POSTGRESQL
spring.datasource.platform=postgres
spring.jpa.show-sql=true
spring.jpa.hibernate.ddl-auto=none
spring.database.driverClassName=org.postgresql.Driver
spring.devtools.livereload.enabled = false

endpoints.cors.allowed-origins=*
spring.jpa.show-sql=false
#logging.level.org.springframework.web=DEBUG
#logging.level.org.hibernate.SQL=DEBUG
#logging.file = coderec.log
#logging.config = classpath:logback.xml


############################## INPUT PARAMETERS ######################################

spring.datasource.url=jdbc:postgresql://localhost:5432/stackoverflow2018msr2019java
spring.datasource.username=postgres
spring.datasource.password=lascampostgres5k


#### app environment variables
useProxy=false
environment=development
virutalPythonEnv=


######### Must be set
BIKER_HOME=/home/rodrigo/projects/BIKER/StackOverflow
CROKAGE_HOME=/home/rodrigo/Dropbox/Doutorado/projects/bot
TMP_DIR=/home/rodrigo/tmp
FAST_TEXT_INSTALLATION_DIR=/home/rodrigo/projects/fastText-0.1.0

######### Must to be provided or generated via method call

BIKER_RUNNER_PATH=biker_runner_external_queries.py
#generated model path
FAST_TEXT_MODEL_PATH = ${TMP_DIR}/fastTextModel.bin
# generated by method call - a map containing all apis and their answers ids
BIG_MAP_INVERTED_INDEX_APIS_FILE_PATH = ${TMP_DIR}/bigMap.txt
# generated by method call - a map containing apis with a minimum count number
REDUCED_MAP_INVERTED_INDEX_APIS_FILE_PATH = ${TMP_DIR}/reducedMapReport.csv
# generated by method call by the same method above - answer ids disconsidered because have no api calls
DISCONSIDERED_POSTS_FILE_PATH = ${TMP_DIR}/disconsideredPostsBigMap.txt
# generated by method call.
SO_ANSWERS_IDS_PARENT_IDS_MAP = ${TMP_DIR}/soAnswersIdsParentsIds.txt
# generated by method call. Contains ids and titles from SO questions.
SO_QUESTIONS_IDS_TITLES_MAP = ${TMP_DIR}/soQuestionsIdsTitles.txt
# generated by method call. Contains titles, bodies and code of SO posts, one per line
SO_CONTENT_FILE = ${TMP_DIR}/soContent.txt
# generated by method call. From so content file, calculate the idf of all words and save in this file.
SO_IDF_VOCABULARY = ${TMP_DIR}/soIDFVocabulary.txt
# generated by method call. From the idf file, build a file containing the non-repeated words of SO. Used to build the vectors for all words.
SO_SET_OF_WORDS = ${TMP_DIR}/soSetOfWords.txt
# generated in shell through fastText commands. Uses the file above. Contains word vectors for each word of the titles vocabulary.
SO_CONTENT_WORD_VECTORS = ${TMP_DIR}/soContentWordVec.txt
# generated by method call. To be used by lucene to build idf voc.
SO_DIRECTORY_FILES =  ${TMP_DIR}/sodirectory
# generated by method call. To be used by lucene to build idf voc.
SO_DIRECTORY_INDEX =  ${TMP_DIR}/sodirindex
# generated by method call. Top k results for google search.
GOOGLE_TOP_RESULTS_FOR_NLP2API = ${CROKAGE_HOME}/data/googleNLP2ApiResults-all-questions.txt
# questions not relevant enought for evaluation
GOOGLE_EXCEPTIONS_FOR_NLP2API = ${CROKAGE_HOME}/data/googleExceptionsForNLP2ApiQuestions.txt
# to evaluate questions to queries
NLP2API_QUERIES_AND_SO_QUESTIONS_TO_EVALUATE =${CROKAGE_HOME}/data/NLP2APISOQuestionsToEvaluate.csv


######### Must to be generated or provided for tests

 #for tests - static file - must be provided
NLP2API_GOLD_SET_FILE = ${CROKAGE_HOME}/data/nlp2ApiGoldSet.txt
#for tests - provided or generated by reading excel file containing evaluations
INPUT_QUERIES_FILE_CROKAGE = ${CROKAGE_HOME}/data/inputQueriesCrokage.txt
#for tests -provided or generated by reading excel file containing evaluations
INPUT_QUERIES_FILE_NLP2API = ${CROKAGE_HOME}/data/inputQueriesNlp2Api.txt

STOP_WORDS_FILE_PATH=${CROKAGE_HOME}/data/stanford_stop_words.txt

######### Automatically generated files

#generated to be read by BIKER
BIKER_INPUT_QUERIES_FILE = ${BIKER_HOME}/data/inputQueries
#generated by BIKER
BIKER_OUTPUT_QUERIES_FILE = ${BIKER_HOME}/data/queriesApisOutput.txt
#generated to call biker approach
BIKER_SCRIPT_FILE = /tmp/bikerCaller.sh
#generated to feed RACK jar
RACK_INPUT_QUERIES_FILE = ${CROKAGE_HOME}/data/rackApiQueriesInput.txt
#generated after calling NLP2Api jar
RACK_OUTPUT_QUERIES_FILE = ${CROKAGE_HOME}/data/rackApiQueriesOutput.txt
#generated to feed NLP2Api jar
NLP2API_INPUT_QUERIES_FILE = ${CROKAGE_HOME}/data/nlp2apiQueriesInput.txt
#generated after calling NLP2Api jar
NLP2API_OUTPUT_QUERIES_FILE = ${CROKAGE_HOME}/data/nlp2apiQueriesOutput.txt



################ API tools actions

# tester							      = used for tests  
# checkConditions						 = used to check conditions to run the approach
# generateGoogleRelatedQuestionsIdsForNLP2Api    = use Google to build top k(numberOfGoogleResults) related questins Ids
# generateGoogleRelatedQuestionsIdsForEvaluation = read the results from Google to NLP2Api questions and build an excel file to be evaluated
# readGoogleRelatedQuestionsIdsForNLP2Api = read top k google results for NLP2API queries
# generateAnswersIdsParentsMap           = used for cache purposes
# readAnswersIdsParentsMap               = used for cache purposes
# generateQuestionsIdsTitlesMap           = used for cache purposes
# readQuestionsIdsTitlesMap               = read generated map
# generateInputQueriesFromExcelGroudTruth = use an excel file to fetch the queries
# generateInputQueriesFromNLP2ApiGroudTruth = use gold set from NLP2Api to generate input queries file
# extractAPIsFromRACK             		  = extracts APIs from RACK approach
# extractAPIsFromBIKER             		  = extracts APIs from BIKER approach
# extractAPIsFromNLP2Api				  = extracts APIs from NLP2Api approach
# loadExcelGroundTruthQuestionsAndLikerts = load excel files containing likerts for external questions - ground truth
# generateMetricsForApiExtractors 		  = extract metrics for the apis. Set subAction to RACK|BIKER|NLP2Api or a combination of them like BIKER|NLP2Api for BICKER + NLP2API or RACK|BIKER|NLP2Api for the three of them (the order matters !) 
#                                           subAction may also contains ...|generateTableForApproaches to print a string that can be used to paste into overleaf representing the lines of a table  
# generateInvertedIndexFileFromSOPosts    = fetches posts containing code, extract classes and build a file with inverted indexes in a format like: api-> postID1, postID2 ...   
# reduceBigMapFileToMininumAPIsCount      = loads the big file, set cutoff to the minimum amount of ids each class should have and generate reduced map
# loadInvertedIndexFile					  = loads the reduced file containing the indexes and stores into a map	
## preprocess another project
# generateTrainingFileToFastText		  = generate a txt file containing all posts contents (pre processed)
## build fastText model .bin              = ./fasttext skipgram -input /home/rodrigo/tmp/soContent.txt -output /home/rodrigo/tmp/fastTextModel -epoch 10 -lr 0.05 -minn 2 -maxn 5 -dim 100
# buildSODirectoryFiles				      = build a txt file representing each post to be used by lucene
# buildLuceneIndex						  = build lucene index	
# buildIDFVocabulary					  = build IDFs for all words in vocabulary	
# readIDFVocabulary					  	  = read IDFs for all words in vocabulary from a file
# buildSOSetOfWords						  = build a txt file with the set of words from SO. For this, read the idf txt file.
## build fastText wordvec txt file        = built by command line. Use .bin model to build the txt file with words and their vectors.
# readSoContentWordVectors				  = read vectors of all words from txt file, previously generated by fastText in shell 
# runApproach							  = use an input query file to recommend answers #best combination of tools: rack|BIKER|NLP2Api
  
action=
subAction=rack|biker|NLP2Api

# if output file for queries (queriesApisOutput.txt) has already been generated, use false to avoid calling approaches again. Use true if output file with queriesApisOutput.txt has not been generated yet.
callBIKERProcess=true
callNLP2ApiProcess=false
callRACKApiProcess=false

# values= crokage|nlp2api  
dataSet=nlp2api

# Number of queries to consider, null to all
limitQueries=100

numberOfAPIClasses=10

#uses when action=reduceBigMapFileToMininumAPIsCount
cutoff=5
topSimilarQuestionsNumber=200
topSimilarAnswersNumber=50

#if true, load vectors only once, not by demand 
iHaveALotOfMemory=false

#if use Google to replace some steps
useGoogleSearch = false   
# max number allowed for the google api is 10
numberOfGoogleResults = 10
APIKEY				= AIzaSyAKwSG8WR7pdnfVCosoXs21O45t096qtKo
CUSTOM_SEARCH_ID    = 001510221793838672117:ix_l9bnjhbq






############################################################################# Old approach - PitBotApp2 ############################################################################################
 
#Phase 1: Select 1/3 of the external questions (without RACK). Run steps 2 to 9 for each question using features default weights (all set to 0.5) and adjuster default weights (all set to 1.0) and store posts according to their ranking order. Also, after step 6, store all related posts for each question.
     #11: first lot of 11 questions of each site
     #12: second lot of 11 questions of each site 
     #13: adjustments and fixes
#Phase 2: Run internal survey for the selected questions in Phase 1 to evaluate answers. For each question, retrieve the ranked posts previously stored. Store the evaluation of each user.
	 #11: first lot of 11 questions of each site
     #12: second lot of 11 questions of each site
#Phase 3: 
     #3.1: Build excel with evaluations. Manually open spreadsheet with libreoffice and follow the steps as in instructionsToAgreementPhaseLinks.txt . Agreement phase. 
     #3.2: Use previous xlsx spreedShed to build a matrix of values for the scales - before agreement
     #3.3: Use previous xlsx spreedShed to build a matrix of values for the scales - after agreement
     #3.4: Discover the best adjuster weights. Use the previous xlsx to load the scales and discover what is the influence of the post origin to the post quality. Set adjuster weights.
#Phase 4: Select another 1/3 of the remaining questions and run the approach like in phase 1. - Using adjuster weights.
	 #41: first lot of 11 questions of each site
     #42: second lot of 11 questions of each site 
#Phase 5: Repeat phase 2 (internal survey) for the selected questions. 
#Phase 6: 
     #6.1: Build excel with evaluations. Manually open spreadsheet with libreoffice and follow the steps as in instructionsToAgreementPhaseLinks.txt . Agreement phase. 
     #6.2: Use previous xlsx spreedShed to build a matrix of values for the scales - before agreement
     #6.3: Use previous xlsx spreedShed to build a matrix of values for the scales - after agreement
     #6.4: Generate ndcg for before and after aplying adjuster weights. Conclude if adjuster weights helped to improve the accuracy.  
     #6.5: Discover the best weights for the composer. For each question, retrieve the previously stored related posts, bootstrap weights, run steps 7 to 9 using each set of weights, build a ranked list and generate recall-rates and mrr. In the end, store the k best results and their weights. Compare perspectives results.
     #6.6: Apply weights. Generade ndcg considering all questions. 
#Phase 7: Using the best set of weights for the composer and the best set of adjuster weights, run the approach for the remaining 1/3 of questions in two perspectives ( with and without rack). 
#Phase 8: Repeat the internal survey for the selected questions.
#Phase 9: Generate mrr for the the two perspectives. Discover which one has the best mrr. 
#Phase 10: For each question in the best evaluated perspective (with or without RACK), retrieve the related posts previously stored, run steps 7 to 9 using the best weights for the composer and store the ranked list. 
#Phase 11: Run external survey to evaluate answers. Load each question and its ranked list and store users evaluations. 
#Phase 12: Use users ratings to generate recall-rates and mrr.
phaseNumber=6

#only valid to some sections
#if phase = 1 or 2, section = 11 or 12. If phase = 4, section = 40
section=4

#possible values: [1,2,3]. Each value correspond to a range of external questions ids.
#1: 1-11; 34-44; 67-77
#2: 12:22; 45-55; 78-88
#3: 23-33; 56-66; 89-99
lot=1

#external question field 
obs = questions without rack
#blank to all
numberOfQueriesToTest =
shuffleListOfQueriesBeforeGoogleSearch = false

#if false, disable RACK tool
runRack = false
numberOfRackClasses = 2





#when performing stemming and removing stop words, prune words with minimum size equals or less than:
minTokenSize=0

#other important control variables

internalSurveyRankListSize=10
externalSurveyRankListSize=10
metricsGenerationRankListSize=15

#ranking weights
alphaCosSim  	  = 0.50
betaCoverageScore = 0.50
gamaCodeSizeScore = 0.50
deltaRepScore     = 0.50
epsilonUpScore    = 0.50

#relation type weights
#relationType_FROM_GOOGLE_QUESTION = 0.56
#relationType_RELATED_DUPE 		  = 0.43
#relationType_RELATED_NOT_DUPE     = 0.36
#relationType_FROM_GOOGLE_ANSWER   = 0.24
#relationType_LINKS_INSIDE_TEXTS   = 0.0
relationType_FROM_GOOGLE_QUESTION = 1
relationType_RELATED_DUPE 		  = 1
relationType_RELATED_NOT_DUPE     = 1
relationType_FROM_GOOGLE_ANSWER   = 1
relationType_LINKS_INSIDE_TEXTS   = 1


